


Create a Self-Service Tool designed to streamline the ML orchestration process. This comprehensive tool will encompass data pipelining, feature engineering, model fine-tuning, retraining, output visualization, and the deployment of models into a production environment.

"This tool should be built by leveraging the existing anomaly detection solution, enabling its repurposing for additional use cases such as data discovery, predictive analysis, and commentary generation."

"The goal of this Self-Service Tool is to expedite the time-to-market for new model implementations by stakeholders, requiring minimal assistance from the GDO team."




The development of the aforementioned self-service tool will be a singular effort, undertaken by a dedicated team comprising full-stack engineers, data engineers, data scientists, and DevOps engineers within GDO. The primary users of this tool will be Subject Matter Experts (SMEs), data scientists, and ML engineers, who will utilize it for the development, customization, and training of new and existing ML models. The introduction of this self-service tool is anticipated to eliminate repetitive and laborious tasks associated with data pipelining, model training, and deployment, thereby enhancing the efficiency of bringing new models to market."

The tool will furnish the end-user with an integrated development environment (IDE) to access a variety of data sources, including SQL and NoSQL databases, Excel files, CSVs, and Parquet files, through the use of data connectors. It will facilitate the creation of datasets for ML ingestion. Additionally, the tool will feature a profiling utility designed to analyze and identify trends in the newly created datasets."

The tool will equip the end-user with an Integrated Development Environment (IDE) that allows access to various data sources, such as SQL and NoSQL databases, Excel, CSV, and Parquet files, through the integration of data connectors. It will also enable users to create and prepare datasets for ingestion into machine learning processes. Furthermore, the tooling includes a profiling utility to facilitate the examination and analysis of newly created datasets, providing insights into underlying patterns and trends


The tool will enable users to select a model from a curated list of standard models for feature engineering, training, and other related tasks.
The tool will provide users with the capability to select and ingest datasets into an ML model of their choice.
he platform will incorporate an editor or Jupyter Notebook integration to facilitate the modification of existing models by the user.
The tool will offer a playground environment where users can experiment with, test, and train their models


Implement tooling that automates the deployment of models to production, enabling users to proceed without the need for direct support from the infrastructure team."
Integrate a feature within the tool that automates the scheduling and execution of ML models in the production environment."
